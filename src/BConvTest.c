#include "conv.h"

#define KERNEL_SIZE (SIZE*SIZE)

/* 以下代码用于测试验证XNOR卷积操作 */
#define BYTE_SIZE 8
#define OUT_CHANNEL 8
#define OUT_BYTE (OUT_CHANNEL/8)
static const uint8_t conv_kernel[KERNEL_SIZE][OUT_BYTE] __attribute__((unused)) = {
    {0x01},
    {0x02},
    {0x04},
    {0x08},
    {0x10},
    {0x20},
    {0x40},
    {0x80},
    {0x81}
};

static const uint8_t mc_conv_kernel[2][KERNEL_SIZE][32/BYTE_SIZE] __attribute__((unused)) = {
{
    {0x01,0x10,0x02,0x20},
    {0x04,0x40,0x08,0x80},
    {0x10,0x81,0x20,0x01},
    {0x40,0x02,0x80,0x04},
    {0x81,0x08,0x01,0x10},
    {0x02,0x20,0x04,0x40},
    {0x08,0x80,0x10,0x81},
    {0x20,0x01,0x40,0x02},
    {0x80,0x04,0x81,0x08},
    },
{
    {0x81,0x10,0x01,0x20},
    {0x02,0x40,0x04,0x80},
    {0x08,0x81,0x10,0x01},
    {0x20,0x02,0x40,0x04},
    {0x80,0x08,0x81,0x10},
    {0x01,0x20,0x02,0x40},
    {0x04,0x80,0x08,0x81},
    {0x10,0x01,0x20,0x02},
    {0x40,0x04,0x80,0x08},
    }, 
};

static const uint8_t depthwise_activate[8*8] __attribute__((unused)) = {
    0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,
    0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,
    0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,
    0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,
    0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,
    0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,
    0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,
    0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,
};

static const uint8_t mc_depthwise_activate[8*8*(32/BYTE_SIZE)] __attribute__((unused)) = {
    0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,
    0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,
    0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,
    0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,
    0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,
    0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,
    0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,
    0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,
    0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,0x01,
    0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,0x02,
    0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,0x04,
    0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,0x08,
    0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,0x10,
    0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,0x20,
    0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,0x40,
    0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,0x80,
};
static const float full_kernel[2][32][9] __attribute__((unused)) =
{
    {
        {
            1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
            -1.0, -1.0, 1.0,
        },
        {
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
            -1.0, -1.0, 1.0,
        },
        {
            1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
        },
        {
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
        },
    },
    {
        {
            1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
        },
        {
            1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
        },
        {
            1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
            -1.0, -1.0, 1.0,
        },
        {
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, -1.0, -1.0,
            -1.0, -1.0, 1.0,
            -1.0, -1.0, -1.0,
        },
        {
            -1.0, 1.0, -1.0,
            -1.0, -1.0, -1.0,
            1.0, -1.0, -1.0,
        },
    },
};

static const float full_activate[32][64] __attribute__((unused)) =
{
    {
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
    },
    {
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
    },
    {
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
    },
    {
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0,
    },
    {
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0,
        -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0,
    },
};

static CONV_KernelTypeDef kernel_t = {
        .size = 3,
        .in_ch = 32,
        .out_ch = 2,
        .kernel = (int8_t *)mc_conv_kernel,
        .binary = BINARY,
    };
static Activate_TypeDef input = {
        .size = 8,
        .ch = 32,
        .active = (int8_t *)mc_depthwise_activate,
        .binary = BINARY,
    };

static CONV_KernelTypeDef kernel_full = {
        .size = 3,
        .in_ch = 32,
        .out_ch = 2,
        .kernel = (float *)full_kernel,
        .binary = FLOAT_BYTE,
    };
static Activate_TypeDef input_full = {
        .size = 8,
        .ch = 32,
        .active = (float *)full_activate,
        .binary = FLOAT_BYTE,
    };

static int test(void){
    Activate_TypeDef *output = BinarizeConv2d(&kernel_t, &input, 1, 1, 1);
    if(output == NULL){
        printf("参数错误或计算错误\n");
        return -1;
    }
    for(uint16_t ch=0; ch<output->ch; ++ch){
        for(uint16_t x_pos=0; x_pos<output->size; ++x_pos){
            printf("\n");
            for(uint16_t y_pos=0; y_pos<output->size; ++y_pos)
                printf("%-3d ",((int16_t*)(output->active))[ch*output->size*output->size+x_pos*output->size+y_pos]);
                // printf("-- ");
        }
        printf("\n------------------------------------------------\n");
    }
    free(output);

    output = Conv2d(&kernel_full, &input_full, 1, 1, 1);
    if(output == NULL){
        printf("参数错误或计算错误\n");
        return -1;
    }
    for(uint16_t ch=0; ch<output->ch; ++ch){
        for(uint16_t x_pos=0; x_pos<output->size; ++x_pos){
            printf("\n");
            for(uint16_t y_pos=0; y_pos<output->size; ++y_pos)
                printf("%-5.1f ",((float*)(output->active))[ch*output->size*output->size+x_pos*output->size+y_pos]);
                // printf("-- ");
        }
        printf("\n------------------------------------------------\n");
    }
    free(output);

    printf("ok!");
    return 1;
}

void trans_tensor(CONV_KernelTypeDef *kernel, Activate_TypeDef *active, bool depthwise){
    uint8_t byte_num;
    if(depthwise){
        byte_num = kernel->in_ch/DATA_LEN;
        for(uint16_t out_ch=0;out_ch<kernel->out_ch; ++out_ch){
            printf("[\n");
            for(uint16_t in_ch=0;in_ch<kernel->in_ch; ++in_ch){
                printf("    [\n");
                for(uint16_t x_size=0;x_size<kernel->size; ++x_size){
                    printf("        [");
                    for(uint16_t y_size=0;y_size<kernel->size; ++y_size)
                        printf("%d.0, ",(((((intx_t*)(kernel->kernel))[(out_ch*kernel->size*kernel->size*byte_num)+x_size*kernel->size*byte_num+y_size*byte_num+in_ch/DATA_LEN]>>(in_ch%DATA_LEN))&0x01)?1:-1));
                    printf("],\n");
                }
                printf("    ],\n");
            }
            printf("],\n");
        }
    }
    else{
        byte_num = kernel->out_ch/DATA_LEN;
        for(uint16_t out_ch=0;out_ch<kernel->out_ch; ++out_ch){
            printf("[\n");
            for(uint16_t in_ch=0;in_ch<active->ch; ++in_ch){
                printf("    [\n");
                for(uint16_t x_size=0;x_size<kernel->size; ++x_size){
                    printf("        [");
                    for(uint16_t y_size=0;y_size<kernel->size; ++y_size)
                        printf("%d.0, ",(((((intx_t*)(kernel->kernel))[x_size*kernel->size*byte_num+y_size*byte_num+out_ch/DATA_LEN]>>(out_ch%DATA_LEN))&0x01)?1:-1));
                    printf("],\n");
                }
                printf("    ],\n");
            }
            printf("],\n");
        }
    }

    byte_num = active->ch/DATA_LEN;
    for(uint16_t in_ch=0;in_ch<active->ch; ++in_ch){
        printf("    [\n");
        for(uint16_t x_size=0;x_size<active->size; ++x_size){
            printf("        [");
            for(uint16_t y_size=0;y_size<active->size; ++y_size)
                printf("%d.0, ",(((((intx_t*)(active->active))[x_size*active->size*byte_num+y_size*byte_num+in_ch/DATA_LEN]>>in_ch%DATA_LEN)&0x01)?1:-1));
            printf("],\n");
        }
        printf("    ],\n");
    }
}

void BConvTest(){
    // trans_tensor(&kernel_t, &input, 1);
    test();
}
